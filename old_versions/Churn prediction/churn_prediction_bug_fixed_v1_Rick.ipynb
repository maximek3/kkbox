{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Solution (for transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning library\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "#import XGBOOST Libraries\n",
    "#import xgboost as xgb\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "#Configure Panda\n",
    "pd.options.display.width = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and pre-processing data\n",
    "### !!! ATTENTION: In order to load the following files you first need to completely run the latest versions of Feature_Engineering_Members.ipynb and Feature_Engineering_Transactions.ipynb. !!!\n",
    "### 2.1 Load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load data in\n",
    "train = pd.read_csv('data/train_v2.csv')\n",
    "test = pd.read_csv('data/sample_submission_v2.csv')\n",
    "transactions = pd.read_csv('data/final_transactions.csv')\n",
    "final_members=pd.read_csv('data/final_members.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Merge the different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating datasets witgh input&outputs\n",
    "train_data = pd.merge(train,final_members,on='msno',how='left')\n",
    "train_data = pd.merge(train_data,transactions,how='left',on='msno',left_index=True, right_index=True)\n",
    "\n",
    "# Creating datasets with only inputs\n",
    "# Note that the submission_v2.csv file does NOT contain ouputs (they are all 0)\n",
    "test_data = pd.merge(test,final_members,on='msno',how='left')\n",
    "test_data = pd.merge(test_data,transactions,how='left',on='msno',left_index=True, right_index=True)\n",
    "\n",
    "#print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msno                         0\n",
      "is_churn                     0\n",
      "city_1                  109993\n",
      "city_3                  109993\n",
      "city_4                  109993\n",
      "city_5                  109993\n",
      "city_6                  109993\n",
      "city_7                  109993\n",
      "city_8                  109993\n",
      "city_9                  109993\n",
      "city_10                 109993\n",
      "city_11                 109993\n",
      "city_12                 109993\n",
      "city_13                 109993\n",
      "city_14                 109993\n",
      "city_15                 109993\n",
      "city_16                 109993\n",
      "city_17                 109993\n",
      "city_18                 109993\n",
      "city_19                 109993\n",
      "city_20                 109993\n",
      "city_21                 109993\n",
      "city_22                 109993\n",
      "reg_year_2012           109993\n",
      "reg_year_2013           109993\n",
      "reg_year_2014           109993\n",
      "reg_year_2015           109993\n",
      "reg_year_2016           109993\n",
      "reg_year_2017           109993\n",
      "reg_3                   109993\n",
      "                         ...  \n",
      "plan_list_price_150          0\n",
      "plan_list_price_180          0\n",
      "plan_list_price_210          0\n",
      "plan_list_price_265          0\n",
      "plan_list_price_298          0\n",
      "plan_list_price_300          0\n",
      "plan_list_price_350          0\n",
      "plan_list_price_400          0\n",
      "plan_list_price_447          0\n",
      "plan_list_price_450          0\n",
      "plan_list_price_477          0\n",
      "plan_list_price_480          0\n",
      "plan_list_price_500          0\n",
      "plan_list_price_536          0\n",
      "plan_list_price_596          0\n",
      "plan_list_price_600          0\n",
      "plan_list_price_699          0\n",
      "plan_list_price_799          0\n",
      "plan_list_price_894          0\n",
      "plan_list_price_930          0\n",
      "plan_list_price_1000         0\n",
      "plan_list_price_1150         0\n",
      "plan_list_price_1200         0\n",
      "plan_list_price_1260         0\n",
      "plan_list_price_1299         0\n",
      "plan_list_price_1300         0\n",
      "plan_list_price_1399         0\n",
      "plan_list_price_1599         0\n",
      "plan_list_price_1788         0\n",
      "plan_list_price_2000         0\n",
      "Length: 113, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for null values\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msno                    0\n",
      "is_churn                0\n",
      "city_1                  0\n",
      "city_3                  0\n",
      "city_4                  0\n",
      "city_5                  0\n",
      "city_6                  0\n",
      "city_7                  0\n",
      "city_8                  0\n",
      "city_9                  0\n",
      "city_10                 0\n",
      "city_11                 0\n",
      "city_12                 0\n",
      "city_13                 0\n",
      "city_14                 0\n",
      "city_15                 0\n",
      "city_16                 0\n",
      "city_17                 0\n",
      "city_18                 0\n",
      "city_19                 0\n",
      "city_20                 0\n",
      "city_21                 0\n",
      "city_22                 0\n",
      "reg_year_2012           0\n",
      "reg_year_2013           0\n",
      "reg_year_2014           0\n",
      "reg_year_2015           0\n",
      "reg_year_2016           0\n",
      "reg_year_2017           0\n",
      "reg_3                   0\n",
      "                       ..\n",
      "plan_list_price_150     0\n",
      "plan_list_price_180     0\n",
      "plan_list_price_210     0\n",
      "plan_list_price_265     0\n",
      "plan_list_price_298     0\n",
      "plan_list_price_300     0\n",
      "plan_list_price_350     0\n",
      "plan_list_price_400     0\n",
      "plan_list_price_447     0\n",
      "plan_list_price_450     0\n",
      "plan_list_price_477     0\n",
      "plan_list_price_480     0\n",
      "plan_list_price_500     0\n",
      "plan_list_price_536     0\n",
      "plan_list_price_596     0\n",
      "plan_list_price_600     0\n",
      "plan_list_price_699     0\n",
      "plan_list_price_799     0\n",
      "plan_list_price_894     0\n",
      "plan_list_price_930     0\n",
      "plan_list_price_1000    0\n",
      "plan_list_price_1150    0\n",
      "plan_list_price_1200    0\n",
      "plan_list_price_1260    0\n",
      "plan_list_price_1299    0\n",
      "plan_list_price_1300    0\n",
      "plan_list_price_1399    0\n",
      "plan_list_price_1599    0\n",
      "plan_list_price_1788    0\n",
      "plan_list_price_2000    0\n",
      "Length: 113, dtype: int64\n",
      "msno                    0\n",
      "is_churn                0\n",
      "city_1                  0\n",
      "city_3                  0\n",
      "city_4                  0\n",
      "city_5                  0\n",
      "city_6                  0\n",
      "city_7                  0\n",
      "city_8                  0\n",
      "city_9                  0\n",
      "city_10                 0\n",
      "city_11                 0\n",
      "city_12                 0\n",
      "city_13                 0\n",
      "city_14                 0\n",
      "city_15                 0\n",
      "city_16                 0\n",
      "city_17                 0\n",
      "city_18                 0\n",
      "city_19                 0\n",
      "city_20                 0\n",
      "city_21                 0\n",
      "city_22                 0\n",
      "reg_year_2012           0\n",
      "reg_year_2013           0\n",
      "reg_year_2014           0\n",
      "reg_year_2015           0\n",
      "reg_year_2016           0\n",
      "reg_year_2017           0\n",
      "reg_3                   0\n",
      "                       ..\n",
      "plan_list_price_150     0\n",
      "plan_list_price_180     0\n",
      "plan_list_price_210     0\n",
      "plan_list_price_265     0\n",
      "plan_list_price_298     0\n",
      "plan_list_price_300     0\n",
      "plan_list_price_350     0\n",
      "plan_list_price_400     0\n",
      "plan_list_price_447     0\n",
      "plan_list_price_450     0\n",
      "plan_list_price_477     0\n",
      "plan_list_price_480     0\n",
      "plan_list_price_500     0\n",
      "plan_list_price_536     0\n",
      "plan_list_price_596     0\n",
      "plan_list_price_600     0\n",
      "plan_list_price_699     0\n",
      "plan_list_price_799     0\n",
      "plan_list_price_894     0\n",
      "plan_list_price_930     0\n",
      "plan_list_price_1000    0\n",
      "plan_list_price_1150    0\n",
      "plan_list_price_1200    0\n",
      "plan_list_price_1260    0\n",
      "plan_list_price_1299    0\n",
      "plan_list_price_1300    0\n",
      "plan_list_price_1399    0\n",
      "plan_list_price_1599    0\n",
      "plan_list_price_1788    0\n",
      "plan_list_price_2000    0\n",
      "Length: 113, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Get rid of null-values\n",
    "\n",
    "#For train data\n",
    "#Set city null values to o in train data\n",
    "cities = ['city_1','city_3','city_4','city_5','city_6','city_7','city_8','city_9','city_10','city_11','city_12','city_13','city_14','city_15','city_16','city_17','city_18','city_19','city_20','city_21','city_22']\n",
    "for i in range(0,len(cities)):\n",
    "        inpt = cities[i]\n",
    "        train_data[inpt]=train_data[inpt].fillna(value=0)\n",
    "        test_data[inpt]=test_data[inpt].fillna(value=0)\n",
    "        \n",
    "reg_dates=['reg_year_2012','reg_year_2013','reg_year_2014','reg_year_2015','reg_year_2016','reg_year_2017']        \n",
    "for i in range(0,len(reg_dates)):\n",
    "        inpt = reg_dates[i]\n",
    "        train_data[inpt]=train_data[inpt].fillna(value=0)\n",
    "        test_data[inpt]=test_data[inpt].fillna(value=0)\n",
    "\n",
    "reg_meth=['reg_3','reg_4','reg_7','reg_9','reg_11']\n",
    "for i in range(0,len(reg_meth)):\n",
    "        inpt = reg_meth[i]\n",
    "        train_data[inpt]=train_data[inpt].fillna(value=0)\n",
    "        test_data[inpt]=test_data[inpt].fillna(value=0)     \n",
    "        \n",
    "train_data['bd_norm']=train_data['bd_norm'].fillna(value=0)\n",
    "test_data['bd_norm']=test_data['bd_norm'].fillna(value=0)     \n",
    "\n",
    "train_data['bd']=train_data['bd'].fillna(value=0)\n",
    "test_data['bd']=test_data['bd'].fillna(value=0)\n",
    "\n",
    "#check for null values\n",
    "print(train_data.isnull().sum())\n",
    "print(test_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unwanted columns (this may change with new insights or new code!)\n",
    "unwanted = ['msno','actual_amount_paid','transaction_date','membership_expire_date', 'diff_plan_actual']\n",
    "#Before dropping the msno of test, we need to save it for the sumission\n",
    "msno = test.msno\n",
    "train_data = train_data.drop(unwanted, axis=1)\n",
    "test_data = test_data.drop(unwanted, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970960, 107)\n",
      "(970960,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting input/output data into train and test sets in order to check efficiency of our models\n",
    "data_input = train_data.drop('is_churn',axis=1)\n",
    "data_output = train_data['is_churn']\n",
    "print(data_input.shape)\n",
    "print(data_output.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.2, random_state=42)\n",
    "\n",
    "# Removing is_churn (as it's all dummy zeros) from test data\n",
    "test_input = test_data.drop('is_churn',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Testing out prediction models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest, no training data\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "print('Model fitted!')\n",
    "y_pred_f = model.predict(x_test)\n",
    "print('Prediction done!')\n",
    "print(\"Logloss for Random Forrest is: %.2f\"%log_loss(y_test,y_pred_f))\n",
    "\n",
    "## I think we should use the logloss to measure our accuracy, as it is the same then they use on Kaggle. Also, to use accuracy, we need our input to be only 0's and 1's, thus it is not a very accurate assesment description of our model\n",
    "#predictions = [round(value) for value in y_pred]\n",
    "#accuracy = accuracy_score(y_test, predictions)\n",
    "#print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted!\n",
      "Prediction done!\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "print('Model fitted!')\n",
    "# Make predicitons for test data\n",
    "y_pred_l = model.predict(x_test)\n",
    "y_pred_l = np.absolute(y_pred_l)\n",
    "print('Prediction done!')\n",
    "#print(\"Logloss for Linear Regression is: %.2f\"%log_loss(y_test,y_pred_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run AdaBoost\n",
    "model_abr = AdaBoostRegressor()\n",
    "model_abr.fit(x_train, y_train)\n",
    "y_pred_abr = model_abr.predict(x_test)\n",
    "print(\"Logloss for AdaBoost is: %.2f\"%log_loss(y_test,y_pred_abr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run SGDRegressor (really bad)\n",
    "model_sgd = SGDRegressor()\n",
    "#model_sgd.fit(x_train, y_train)\n",
    "#y_pred_sgd = model_sgd.predict(x_test)\n",
    "print(\"Logloss for SGDRegressor is: %.2f\"%log_loss(y_test,y_pred_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run GradientBoostingRegressor (very slow)\n",
    "model_gbr = GradientBoostingRegressor()\n",
    "#model_gbr.fit(x_train, y_train)\n",
    "#y_pred_gbr = model_gbr.predict(x_test)\n",
    "print(\"Logloss for GradientBoostingRegressor is: %.2f\"%log_loss(y_test,y_pred_gbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#XG Boost\n",
    "dtrain = xgb.DMatrix(x_train, label = y_train)\n",
    "dtest = xgb.DMatrix(x_test, label = y_test)\n",
    "print('Done.')\n",
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree. Try with max_depth: 2 to 10.\n",
    "    'eta': 0.3,  # the training step for each iteration. Try with ETA: 0.1, 0.2, 0.3...\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations. Try with num_round around few hundred!\n",
    "#----------------\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "print('Modeling done!')\n",
    "\n",
    "y_pred_xgb = bst.predict(dtest)\n",
    "print('Prediction done!')\n",
    "\n",
    "best_preds = np.asarray([np.argmax(line) for line in y_pred_xgb])\n",
    "\n",
    "y_pred_xgb = y_pred_xgb[:,1] #Column 2 out of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from  sklearn.metrics import log_loss\n",
    "print(\"Logloss for XGBoost is: %.3f\"%log_loss(y_test,y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Running the best model on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "model.fit(data_input, data_output)\n",
    "y_pred_l = model.predict(test_input)\n",
    "y_pred_l = np.absolute(y_pred_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_churn                                          msno\n",
      "0  0.037626  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=\n",
      "1  0.122158  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=\n",
      "2  0.049215  rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=\n",
      "3  0.054997  WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=\n",
      "4  0.091411  aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=\n",
      "                                           msno  is_churn\n",
      "0  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=  0.037626\n",
      "1  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=  0.122158\n",
      "2  rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=  0.049215\n",
      "3  WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=  0.054997\n",
      "4  aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=  0.091411\n",
      "msno        907471\n",
      "is_churn    907471\n",
      "dtype: int64\n",
      "Done! :-)\n"
     ]
    }
   ],
   "source": [
    "#Prepare submission file\n",
    "my_submission = pd.DataFrame({'msno': msno, 'is_churn': y_pred_l})\n",
    "#think about changing y_pred_1 if you want to use a diffrenet algorithm\n",
    "#y_pred_1 was one of the reasons for the previous bug\n",
    "print(my_submission.head())\n",
    "cols = my_submission.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "my_submission = my_submission[cols]\n",
    "print(my_submission.head())\n",
    "print(my_submission.count())\n",
    "\n",
    "my_submission.to_csv('submission.csv', index=False)\n",
    "print('Done! :-)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments for report:\n",
    "-We should not consider the accuracy, because our set is imbalanced. 95% churns, which is why accuracy is a bad measure\n",
    "-Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
