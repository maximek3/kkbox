{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ragnhildskirdalfrohaug/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/ragnhildskirdalfrohaug/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning library\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "#import XGBOOST Libraries\n",
    "#import xgboost as xgb\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "#Configure Panda\n",
    "pd.options.display.width = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and pre-processing data\n",
    "!!! ATTENTION: In order to load the following files you first need to completely run the latest versions of Feature_Engineering_Members.ipynb and Feature_Engineering_Transactions.ipynb. !!!\n",
    "### 2.1 Load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data in\n",
    "# From train.csv, we will extract the is_churn and use it as the y-label for training. \n",
    "train = pd.read_csv('data/train.csv')\n",
    "\n",
    "# From train_v2.csv (the churn data for march), we will extract the is_churn and use it as the y-label for training\n",
    "test_march = pd.read_csv('data/train_v2.csv')\n",
    "# From sample_submission_v2.csv, we will extract the msno's \n",
    "test = pd.read_csv('data/sample_submission_v2.csv')\n",
    "\n",
    "# This is the input for our model\n",
    "transactions = pd.read_csv('data/final_transactions.csv')\n",
    "final_members=pd.read_csv('data/final_members.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Merge test and test_label\n",
    "To get the exact number of rows required for the submission file. \n",
    "NB! Some msno from sample_submission_v2 does not have a prediction for March, for the msno's without a prediction, the is_churn is set to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           msno  is_churn_x  is_churn_y\n",
      "0  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=           0         0.0\n",
      "1  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=           0         0.0\n",
      "2  rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=           0         0.0\n",
      "3  WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=           0         0.0\n",
      "4  aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=           0         0.0\n",
      "(907471, 2)\n",
      "                                           msno  is_churn_y\n",
      "0  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=         0.0\n",
      "1  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=         0.0\n",
      "2  rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=         0.0\n",
      "3  WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=         0.0\n",
      "4  aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=         0.0\n"
     ]
    }
   ],
   "source": [
    "test_merged = pd.merge(test,test_march, on='msno', how='left')\n",
    "test_label = test_merged\n",
    "print(test_label.head())\n",
    "#Drop the is_churn column from sample_submission_v2.csv (all zeros)\n",
    "test_label = test_label.drop('is_churn_x', axis=1)\n",
    "\n",
    "#Some msno does not have a prediction for march, set all NaN values to 0.\n",
    "test_label = test_label.fillna(0)\n",
    "print(test_label.shape)\n",
    "print(test_label.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Merge the different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating datasets witgh input&outputs\n",
    "train_data = pd.merge(train,final_members,on='msno',how='left')\n",
    "train_data = pd.merge(train_data,transactions,how='left',on='msno',left_index=True, right_index=True)\n",
    "\n",
    "# Creating datasets with only inputs\n",
    "# Note that the submission_v2.csv file does NOT contain ouputs (they are all 0)\n",
    "test_data = pd.merge(test_label,final_members,on='msno',how='left')\n",
    "test_data = pd.merge(test_data,transactions,how='left',on='msno',left_index=True, right_index=True)\n",
    "\n",
    "#print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msno                         0\n",
      "is_churn                     0\n",
      "bd                      115770\n",
      "city_1                  115770\n",
      "city_3                  115770\n",
      "city_4                  115770\n",
      "city_5                  115770\n",
      "city_6                  115770\n",
      "city_7                  115770\n",
      "city_8                  115770\n",
      "city_9                  115770\n",
      "city_10                 115770\n",
      "city_11                 115770\n",
      "city_12                 115770\n",
      "city_13                 115770\n",
      "city_14                 115770\n",
      "city_15                 115770\n",
      "city_16                 115770\n",
      "city_17                 115770\n",
      "city_18                 115770\n",
      "city_19                 115770\n",
      "city_20                 115770\n",
      "city_21                 115770\n",
      "city_22                 115770\n",
      "reg_year_2012           115770\n",
      "reg_year_2013           115770\n",
      "reg_year_2014           115770\n",
      "reg_year_2015           115770\n",
      "reg_year_2016           115770\n",
      "reg_year_2017           115770\n",
      "                         ...  \n",
      "plan_list_price_150          0\n",
      "plan_list_price_180          0\n",
      "plan_list_price_210          0\n",
      "plan_list_price_265          0\n",
      "plan_list_price_298          0\n",
      "plan_list_price_300          0\n",
      "plan_list_price_350          0\n",
      "plan_list_price_400          0\n",
      "plan_list_price_447          0\n",
      "plan_list_price_450          0\n",
      "plan_list_price_477          0\n",
      "plan_list_price_480          0\n",
      "plan_list_price_500          0\n",
      "plan_list_price_536          0\n",
      "plan_list_price_596          0\n",
      "plan_list_price_600          0\n",
      "plan_list_price_699          0\n",
      "plan_list_price_799          0\n",
      "plan_list_price_894          0\n",
      "plan_list_price_930          0\n",
      "plan_list_price_1000         0\n",
      "plan_list_price_1150         0\n",
      "plan_list_price_1200         0\n",
      "plan_list_price_1260         0\n",
      "plan_list_price_1299         0\n",
      "plan_list_price_1300         0\n",
      "plan_list_price_1399         0\n",
      "plan_list_price_1599         0\n",
      "plan_list_price_1788         0\n",
      "plan_list_price_2000         0\n",
      "Length: 117, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for null values\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msno                         0\n",
      "is_churn                     0\n",
      "bd                      115770\n",
      "city_1                       0\n",
      "city_3                       0\n",
      "city_4                       0\n",
      "city_5                       0\n",
      "city_6                       0\n",
      "city_7                       0\n",
      "city_8                       0\n",
      "city_9                       0\n",
      "city_10                      0\n",
      "city_11                      0\n",
      "city_12                      0\n",
      "city_13                      0\n",
      "city_14                      0\n",
      "city_15                      0\n",
      "city_16                      0\n",
      "city_17                      0\n",
      "city_18                      0\n",
      "city_19                      0\n",
      "city_20                      0\n",
      "city_21                      0\n",
      "city_22                      0\n",
      "reg_year_2012                0\n",
      "reg_year_2013                0\n",
      "reg_year_2014                0\n",
      "reg_year_2015                0\n",
      "reg_year_2016                0\n",
      "reg_year_2017                0\n",
      "                         ...  \n",
      "plan_list_price_150          0\n",
      "plan_list_price_180          0\n",
      "plan_list_price_210          0\n",
      "plan_list_price_265          0\n",
      "plan_list_price_298          0\n",
      "plan_list_price_300          0\n",
      "plan_list_price_350          0\n",
      "plan_list_price_400          0\n",
      "plan_list_price_447          0\n",
      "plan_list_price_450          0\n",
      "plan_list_price_477          0\n",
      "plan_list_price_480          0\n",
      "plan_list_price_500          0\n",
      "plan_list_price_536          0\n",
      "plan_list_price_596          0\n",
      "plan_list_price_600          0\n",
      "plan_list_price_699          0\n",
      "plan_list_price_799          0\n",
      "plan_list_price_894          0\n",
      "plan_list_price_930          0\n",
      "plan_list_price_1000         0\n",
      "plan_list_price_1150         0\n",
      "plan_list_price_1200         0\n",
      "plan_list_price_1260         0\n",
      "plan_list_price_1299         0\n",
      "plan_list_price_1300         0\n",
      "plan_list_price_1399         0\n",
      "plan_list_price_1599         0\n",
      "plan_list_price_1788         0\n",
      "plan_list_price_2000         0\n",
      "Length: 117, dtype: int64\n",
      "msno                         0\n",
      "is_churn_y                   0\n",
      "bd                      112381\n",
      "city_1                       0\n",
      "city_3                       0\n",
      "city_4                       0\n",
      "city_5                       0\n",
      "city_6                       0\n",
      "city_7                       0\n",
      "city_8                       0\n",
      "city_9                       0\n",
      "city_10                      0\n",
      "city_11                      0\n",
      "city_12                      0\n",
      "city_13                      0\n",
      "city_14                      0\n",
      "city_15                      0\n",
      "city_16                      0\n",
      "city_17                      0\n",
      "city_18                      0\n",
      "city_19                      0\n",
      "city_20                      0\n",
      "city_21                      0\n",
      "city_22                      0\n",
      "reg_year_2012                0\n",
      "reg_year_2013                0\n",
      "reg_year_2014                0\n",
      "reg_year_2015                0\n",
      "reg_year_2016                0\n",
      "reg_year_2017                0\n",
      "                         ...  \n",
      "plan_list_price_150          0\n",
      "plan_list_price_180          0\n",
      "plan_list_price_210          0\n",
      "plan_list_price_265          0\n",
      "plan_list_price_298          0\n",
      "plan_list_price_300          0\n",
      "plan_list_price_350          0\n",
      "plan_list_price_400          0\n",
      "plan_list_price_447          0\n",
      "plan_list_price_450          0\n",
      "plan_list_price_477          0\n",
      "plan_list_price_480          0\n",
      "plan_list_price_500          0\n",
      "plan_list_price_536          0\n",
      "plan_list_price_596          0\n",
      "plan_list_price_600          0\n",
      "plan_list_price_699          0\n",
      "plan_list_price_799          0\n",
      "plan_list_price_894          0\n",
      "plan_list_price_930          0\n",
      "plan_list_price_1000         0\n",
      "plan_list_price_1150         0\n",
      "plan_list_price_1200         0\n",
      "plan_list_price_1260         0\n",
      "plan_list_price_1299         0\n",
      "plan_list_price_1300         0\n",
      "plan_list_price_1399         0\n",
      "plan_list_price_1599         0\n",
      "plan_list_price_1788         0\n",
      "plan_list_price_2000         0\n",
      "Length: 117, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Get rid of null-values\n",
    "\n",
    "#For train data\n",
    "#Set city null values to o in train data\n",
    "cities = ['city_1','city_3','city_4','city_5','city_6','city_7','city_8','city_9','city_10','city_11','city_12','city_13','city_14','city_15','city_16','city_17','city_18','city_19','city_20','city_21','city_22']\n",
    "for i in range(0,len(cities)):\n",
    "        inpt = cities[i]\n",
    "        train_data[inpt]=train_data[inpt].fillna(value=0)\n",
    "        test_data[inpt]=test_data[inpt].fillna(value=0)\n",
    "        \n",
    "reg_dates=['reg_year_2012','reg_year_2013','reg_year_2014','reg_year_2015','reg_year_2016','reg_year_2017']        \n",
    "for i in range(0,len(reg_dates)):\n",
    "        inpt = reg_dates[i]\n",
    "        train_data[inpt]=train_data[inpt].fillna(value=0)\n",
    "        test_data[inpt]=test_data[inpt].fillna(value=0)\n",
    "\n",
    "reg_meth=['reg_3','reg_4','reg_7','reg_9','reg_11']\n",
    "for i in range(0,len(reg_meth)):\n",
    "        inpt = reg_meth[i]\n",
    "        train_data[inpt]=train_data[inpt].fillna(value=0)\n",
    "        test_data[inpt]=test_data[inpt].fillna(value=0)     \n",
    "        \n",
    "#train_data['bd_norm ']=train_data['bd_norm'].fillna(value=0)\n",
    "#test_data['bd_norm']=test_data['bd_norm'].fillna(value=0)     \n",
    "\n",
    "#Set registration dates null values to o in train data\n",
    "#train_data[['reg_year_2017']] = train_data[['reg_year_2017']].fillna(value=0)\n",
    "#test_data[['reg_year_2017']] = test_data[['reg_year_2017']].fillna(value=0)\n",
    "\n",
    "#check for null values\n",
    "print(train_data.isnull().sum())\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unwanted columns (this may change with new insights or new code!)\n",
    "unwanted = ['msno','transaction_date','membership_expire_date']\n",
    "#Before dropping the msno of test, we need to save it for the sumission\n",
    "msno = test_march.msno\n",
    "train_data = train_data.drop(unwanted, axis=1)\n",
    "test_data = test_data.drop(unwanted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(992931, 113)\n",
      "(992931,)\n",
      "(907471, 113)\n",
      "(907471,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting input/output data into train and test sets in order to check efficiency of our models\n",
    "data_input = train_data.drop('is_churn',axis=1)\n",
    "data_output = train_data['is_churn']\n",
    "print(data_input.shape)\n",
    "print(data_output.shape)\n",
    "\n",
    "# Removing is_churn (as it's all dummy zeros) from test data\n",
    "test_input = test_data.drop('is_churn_y',axis=1)\n",
    "test_output = test_label['is_churn_y']\n",
    "print(test_input.shape)\n",
    "print(test_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Modeling done!\n",
      "Prediction done!\n"
     ]
    }
   ],
   "source": [
    "#XG Boost\n",
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(data_input, label = data_output)\n",
    "dtest = xgb.DMatrix(test_input, label = test_output)\n",
    "print('Done.')\n",
    "param = {\n",
    "    'max_depth': 4,  # the maximum depth of each tree. Try with max_depth: 2 to 10.\n",
    "    'eta': 0.3,  # the training step for each iteration. Try with ETA: 0.1, 0.2, 0.3...\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations. Try with num_round around few hundred!\n",
    "#----------------\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "print('Modeling done!')\n",
    "\n",
    "y_pred_xgb = bst.predict(dtest)\n",
    "print('Prediction done!')\n",
    "\n",
    "best_preds = np.asarray([np.argmax(line) for line in y_pred_xgb])\n",
    "\n",
    "y_pred_xgb = y_pred_xgb[:,1] #Column 2 out of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss for XGBoost is: 0.097\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import log_loss\n",
    "y = test_data[test_data.columns[0]]\n",
    "print(\"Logloss for XGBoost is: %.3f\"%log_loss(y,y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Creating submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_churn                                          msno\n",
      "0  0.016168  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=\n",
      "1  0.058358  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=\n",
      "2  0.040174  rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=\n",
      "3  0.046575  WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=\n",
      "4  0.167030  aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=\n",
      "                                           msno  is_churn\n",
      "0  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=  0.016168\n",
      "1  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=  0.058358\n",
      "2  rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=  0.040174\n",
      "3  WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=  0.046575\n",
      "4  aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=  0.167030\n",
      "msno        907471\n",
      "is_churn    907471\n",
      "dtype: int64\n",
      "Done! :-)\n"
     ]
    }
   ],
   "source": [
    "#Prepare submission file\n",
    "my_submission = pd.DataFrame({'msno': msno, 'is_churn': y_pred_xgb})\n",
    "#think about changing y_pred_1 if you want to use a diffrenet algorithm\n",
    "#y_pred_1 was one of the reasons for the previous bug\n",
    "print(my_submission.head())\n",
    "cols = my_submission.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "my_submission = my_submission[cols]\n",
    "print(my_submission.head())\n",
    "print(my_submission.count())\n",
    "\n",
    "my_submission.to_csv('submission_3.csv', index=False)\n",
    "print('Done! :-)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impoirt libraries for cross validation\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation with XGBoost (really slow, 30 - 45 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline created.\n",
      "[-0.21899533 -0.21797433 -0.21844548]\n",
      "Log Loss 0.218472\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Create the pipeline\n",
    "my_pipeline = make_pipeline(Imputer(), xgb.XGBClassifier())\n",
    "print('Pipeline created.')\n",
    "#Get cross validation scores\n",
    "scores = cross_val_score(my_pipeline, data_input, data_output, scoring='neg_log_loss', cv=3)\n",
    "print(scores)\n",
    "\n",
    "#Single measure of model quality\n",
    "print('Log Loss %2f' %(-1 * scores.mean()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
