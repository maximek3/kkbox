{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Solution (for transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning library\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "#import XGBOOST Libraries\n",
    "#import xgboost as xgb\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "#Configure Panda\n",
    "pd.options.display.width = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and pre-processing data\n",
    "### !!! ATTENTION: In order to load the following files you first need to completely run Feature_Engineering_Members.ipynb and Feature_Engineering_Transactions.ipynb. !!!\n",
    "### 2.1 Load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city_1</th>\n",
       "      <th>city_3</th>\n",
       "      <th>city_4</th>\n",
       "      <th>city_5</th>\n",
       "      <th>city_6</th>\n",
       "      <th>city_7</th>\n",
       "      <th>city_8</th>\n",
       "      <th>city_9</th>\n",
       "      <th>city_10</th>\n",
       "      <th>...</th>\n",
       "      <th>city_15</th>\n",
       "      <th>city_16</th>\n",
       "      <th>city_17</th>\n",
       "      <th>city_18</th>\n",
       "      <th>city_19</th>\n",
       "      <th>city_20</th>\n",
       "      <th>city_21</th>\n",
       "      <th>city_22</th>\n",
       "      <th>reg_name</th>\n",
       "      <th>reg_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city_1  city_3  city_4  city_5  city_6  city_7  city_8  city_9  city_10    ...      city_15  city_16  city_17  city_18  city_19  city_20  city_21  \\\n",
       "0  Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=       1       0       0       0       0       0       0       0        0    ...            0        0        0        0        0        0        0   \n",
       "1  +tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=       1       0       0       0       0       0       0       0        0    ...            0        0        0        0        0        0        0   \n",
       "2  cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=       1       0       0       0       0       0       0       0        0    ...            0        0        0        0        0        0        0   \n",
       "3  9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=       1       0       0       0       0       0       0       0        0    ...            0        0        0        0        0        0        0   \n",
       "4  WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=       0       0       0       0       1       0       0       0        0    ...            0        0        0        0        0        0        0   \n",
       "\n",
       "   city_22  reg_name  reg_month  \n",
       "0        0      2011          9  \n",
       "1        0      2011          9  \n",
       "2        0      2011          9  \n",
       "3        0      2011          9  \n",
       "4        0      2011          9  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data in\n",
    "train = pd.read_csv('data/train_v2.csv')\n",
    "test = pd.read_csv('data/sample_submission_v2.csv')\n",
    "transactions = pd.read_csv('data/final_transactions.csv')\n",
    "final_members=pd.read_csv('data/final_members.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Merge the different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970960, 143)\n"
     ]
    }
   ],
   "source": [
    "# Creating datasets witgh input&outputs\n",
    "train_data = pd.merge(train,final_members,on='msno',how='left')\n",
    "train_data = pd.merge(train_data,transactions,how='left',on='msno',left_index=True, right_index=True)\n",
    "\n",
    "# Creating datasets with only inputs\n",
    "# Note that the submission_v2.csv file does NOT contain ouputs (they are all 0)\n",
    "test_data = pd.merge(test,final_members,on='msno',how='left')\n",
    "test_data = pd.merge(test_data,transactions,how='left',on='msno',left_index=True, right_index=True)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msno                           0\n",
      "is_churn                       0\n",
      "city_1                    109993\n",
      "city_3                    109993\n",
      "city_4                    109993\n",
      "city_5                    109993\n",
      "city_6                    109993\n",
      "city_7                    109993\n",
      "city_8                    109993\n",
      "city_9                    109993\n",
      "city_10                   109993\n",
      "city_11                   109993\n",
      "city_12                   109993\n",
      "city_13                   109993\n",
      "city_14                   109993\n",
      "city_15                   109993\n",
      "city_16                   109993\n",
      "city_17                   109993\n",
      "city_18                   109993\n",
      "city_19                   109993\n",
      "city_20                   109993\n",
      "city_21                   109993\n",
      "city_22                   109993\n",
      "reg_name                  109993\n",
      "reg_month                 109993\n",
      "actual_amount_paid             0\n",
      "is_auto_renew                  0\n",
      "transaction_date               0\n",
      "membership_expire_date         0\n",
      "is_cancel                      0\n",
      "                           ...  \n",
      "plan_list_price_150            0\n",
      "plan_list_price_180            0\n",
      "plan_list_price_210            0\n",
      "plan_list_price_265            0\n",
      "plan_list_price_298            0\n",
      "plan_list_price_300            0\n",
      "plan_list_price_350            0\n",
      "plan_list_price_400            0\n",
      "plan_list_price_447            0\n",
      "plan_list_price_450            0\n",
      "plan_list_price_477            0\n",
      "plan_list_price_480            0\n",
      "plan_list_price_500            0\n",
      "plan_list_price_536            0\n",
      "plan_list_price_596            0\n",
      "plan_list_price_600            0\n",
      "plan_list_price_699            0\n",
      "plan_list_price_799            0\n",
      "plan_list_price_894            0\n",
      "plan_list_price_930            0\n",
      "plan_list_price_1000           0\n",
      "plan_list_price_1150           0\n",
      "plan_list_price_1200           0\n",
      "plan_list_price_1260           0\n",
      "plan_list_price_1299           0\n",
      "plan_list_price_1300           0\n",
      "plan_list_price_1399           0\n",
      "plan_list_price_1599           0\n",
      "plan_list_price_1788           0\n",
      "plan_list_price_2000           0\n",
      "Length: 149, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for null values\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of null-values\n",
    "\n",
    "#For train data\n",
    "#Set city null values to o in train data\n",
    "cities = ['city_1','city_3','city_4','city_5','city_6','city_7','city_8','city_9','city_10','city_11','city_12','city_13','city_14','city_15','city_16','city_17','city_18','city_19','city_20','city_21','city_22']\n",
    "for i in range(0,len(cities)):\n",
    "        inpt = cities[i]\n",
    "        train_data[inpt]=train_data[inpt].fillna(value=0)\n",
    "        test_data[inpt]=test_data[inpt].fillna(value=0)\n",
    "\n",
    "#Set registration dates null values to o in train data\n",
    "train_data[['reg_name','reg_month']] = train_data[['reg_name','reg_month']].fillna(value=0)\n",
    "test_data[['reg_name','reg_month']] = test_data[['reg_name','reg_month']].fillna(value=0)\n",
    "\n",
    "#check for null values\n",
    "#print(train_data.isnull().sum())\n",
    "#print(test_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unwanted columns (this may change with new insights or new code!)\n",
    "unwanted = ['msno','actual_amount_paid','transaction_date','membership_expire_date', 'diff_plan_actual','reg_name','reg_name']\n",
    "train_data = train_data.drop(unwanted, axis=1)\n",
    "test_data = test_data.drop(unwanted, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970960, 142)\n",
      "(970960,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting input/output data into train and test sets in order to check efficiency of our models\n",
    "data_input = train_data.drop('is_churn',axis=1)\n",
    "data_output = train_data['is_churn']\n",
    "print(data_input.shape)\n",
    "print(data_output.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.2, random_state=42)\n",
    "\n",
    "# Removing is_churn (as it's all dummy zeros) from test data\n",
    "test_input = test_data.drop('is_churn',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Testing out prediction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted!\n",
      "Prediction done!\n",
      "Logloss is: 0.40\n"
     ]
    }
   ],
   "source": [
    "# Random Forrest, no training data\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "print('Model fitted!')\n",
    "y_pred_f = model.predict(x_test)\n",
    "print('Prediction done!')\n",
    "print(\"Logloss for Random Forrest is: %.2f\"%log_loss(y_test,y_pred_f))\n",
    "\n",
    "## I think we should use the logloss to measure our accuracy, as it is the same then they use on Kaggle. Also, to use accuracy, we need our input to be only 0's and 1's, thus it is not a very accurate assesment description of our model\n",
    "#predictions = [round(value) for value in y_pred]\n",
    "#accuracy = accuracy_score(y_test, predictions)\n",
    "#print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted!\n",
      "[0.13832868 0.05314634 0.13706256 ... 0.13219336 0.07228248 0.05326477]\n",
      "Prediction done!\n",
      "Logloss for Linear Regression is: 0.30\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "print('Model fitted!')\n",
    "# Make predicitons for test data\n",
    "y_pred_l = model.predict(x_test)\n",
    "y_pred_l = np.absolute(y_pred_l)\n",
    "print('Prediction done!')\n",
    "print(\"Logloss for Linear Regression is: %.2f\"%log_loss(y_test,y_pred_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss for AdaBoost is: 0.30\n"
     ]
    }
   ],
   "source": [
    "# Run AdaBoost\n",
    "model_abr = AdaBoostRegressor()\n",
    "model_abr.fit(x_train, y_train)\n",
    "y_pred_abr = model_abr.predict(x_test)\n",
    "print(\"Logloss for AdaBoost is: %.2f\"%log_loss(y_test,y_pred_abr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximekayser/miniconda3/envs/kkbox/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss for AdaBoost is: 27.72\n"
     ]
    }
   ],
   "source": [
    "# Run SGDRegressor (really bad)\n",
    "model_sgd = SGDRegressor()\n",
    "#model_sgd.fit(x_train, y_train)\n",
    "#y_pred_sgd = model_sgd.predict(x_test)\n",
    "print(\"Logloss for SGDRegressor is: %.2f\"%log_loss(y_test,y_pred_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss for AdaBoost is: 0.30\n"
     ]
    }
   ],
   "source": [
    "# Run GradientBoostingRegressor (very slow)\n",
    "model_gbr = GradientBoostingRegressor()\n",
    "#model_gbr.fit(x_train, y_train)\n",
    "#y_pred_gbr = model_gbr.predict(x_test)\n",
    "print(\"Logloss for GradientBoostingRegressor is: %.2f\"%log_loss(y_test,y_pred_gbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Running the best model on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "model.fit(data_input, data_output)\n",
    "y_pred_l = model.predict(test_input)\n",
    "y_pred_l = np.absolute(y_pred_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_churn                                          msno\n",
      "0  0.061539  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=\n",
      "1  0.122253  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=\n",
      "2  0.125351  rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=\n",
      "3  0.058105  WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=\n",
      "4  0.055695  aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=\n",
      "                                           msno  is_churn\n",
      "0  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=  0.061539\n",
      "1  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=  0.122253\n",
      "2  rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=  0.125351\n",
      "3  WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=  0.058105\n",
      "4  aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=  0.055695\n",
      "msno        907471\n",
      "is_churn    907471\n",
      "dtype: int64\n",
      "Done! :-)\n"
     ]
    }
   ],
   "source": [
    "#Prepare submission file\n",
    "my_submission = pd.DataFrame({'msno': msno, 'is_churn': y_pred_l})\n",
    "print(my_submission.head())\n",
    "cols = my_submission.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "my_submission = my_submission[cols]\n",
    "print(my_submission.head())\n",
    "print(my_submission.count())\n",
    "\n",
    "my_submission.to_csv('submission.csv', index=False)\n",
    "print('Done! :-)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
