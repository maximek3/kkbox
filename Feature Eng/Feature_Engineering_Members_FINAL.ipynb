{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering (Members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This files generates feautures for \"members.csv\" and exports three files called members_train1, members_train2 and members_total. These files are already merged with the two training sets and with the submission file. As such, in the algorithm file, we only need to load the feature-engineered files of members in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the relevant libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpld3\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Configure Panda\n",
    "pd.options.display.width = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load members in:\n",
    "members= pd.read_csv(\"data/members_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "members:\n",
      "                                           msno  city  bd  gender  registered_via  registration_init_time\n",
      "0  Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=     1   0     NaN              11                20110911\n",
      "1  +tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=     1   0     NaN               7                20110914\n",
      "2  cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=     1   0     NaN              11                20110915\n",
      "3  9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=     1   0     NaN              11                20110915\n",
      "4  WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=     6  32  female               9                20110915\n"
     ]
    }
   ],
   "source": [
    "#Look at the first values in members:\n",
    "print(\"members:\")\n",
    "print(members.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we are going to generate features for the members file. In the data analysis of members, we concluded that certain variables such as the birthday or the city users live in have an influence on whether people churn or not. As the quantity as well as the quality of the features have a large influence on the quality of the outcome of the algorithm, it is important to carefully generate and test these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Hot-encoding of city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To include infromation about the city of the user as a feature, we hot-encode the variable \"city\". Indeed, city is a categorical integer variable. As such, the value in \"city\" has no actual numerical meaning. In this case, it is used to describe the city in which the user lives. Alternatively, the cities could also have been designated by their actual name, or a different categorical value, such as \"A\", \"B\", etc. Summing up the values would make no sense. In addition, a city containg a high value does not have a higher importance. Before we handle information about the city to the algorithm, we need to binarize it.\n",
    "If a varable is one-hot encoded, a new column is generated for every possible value that the variable could take. The variable \"city\" contains 21 different cities. As a result, hot-encoding will generate 21 columns containing only 1's and 0's. If a costumer lives in city 3 for example, only the newly generated column \"city_3\" will contain a 1, while the other 20 columns contain a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many unique values does the variable city have?\n",
    "members.city.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>city_1</th>\n",
       "      <th>city_3</th>\n",
       "      <th>city_4</th>\n",
       "      <th>city_5</th>\n",
       "      <th>city_6</th>\n",
       "      <th>...</th>\n",
       "      <th>city_13</th>\n",
       "      <th>city_14</th>\n",
       "      <th>city_15</th>\n",
       "      <th>city_16</th>\n",
       "      <th>city_17</th>\n",
       "      <th>city_18</th>\n",
       "      <th>city_19</th>\n",
       "      <th>city_20</th>\n",
       "      <th>city_21</th>\n",
       "      <th>city_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>20110911</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20110914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>20110915</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>20110915</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=</td>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>20110915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  bd  gender  registered_via  registration_init_time  city_1  city_3  city_4  city_5  city_6   ...     city_13  city_14  city_15  city_16  city_17  \\\n",
       "0  Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=   0     NaN              11                20110911       1       0       0       0       0   ...           0        0        0        0        0   \n",
       "1  +tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=   0     NaN               7                20110914       1       0       0       0       0   ...           0        0        0        0        0   \n",
       "2  cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=   0     NaN              11                20110915       1       0       0       0       0   ...           0        0        0        0        0   \n",
       "3  9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=   0     NaN              11                20110915       1       0       0       0       0   ...           0        0        0        0        0   \n",
       "4  WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=  32  female               9                20110915       0       0       0       0       1   ...           0        0        0        0        0   \n",
       "\n",
       "   city_18  city_19  city_20  city_21  city_22  \n",
       "0        0        0        0        0        0  \n",
       "1        0        0        0        0        0  \n",
       "2        0        0        0        0        0  \n",
       "3        0        0        0        0        0  \n",
       "4        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One-hot encode the cities. \n",
    "#Instead of having a variable called city with values from 1-22, the alorithm performs better with 0's and 1's ->onehot encoding\n",
    "\n",
    "#Generate our final file called final1\n",
    "final1 = members\n",
    "\n",
    "#One-hot encode city and save it into city_encde\n",
    "city_encode = pd.get_dummies(final1['city'],prefix='city')\n",
    "\n",
    "#Drop variable city in final2, as it is no longer needed\n",
    "final1=final1.drop('city',axis=1)\n",
    "\n",
    "#Join the encoded city_encode\n",
    "final1 = final1.join(city_encode)\n",
    "\n",
    "final1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Hot-encoding of the year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we one-hot encode the year of registration. As long as a date is not calculated in relation to another date, the value can be considered as a categorical one. First, we need to convert the integer date to the data type \"date\". This will allow us to extract the year. We showed in the data exploration that the chance of churning is higher for short-term users. We are going to consider the dates until the year 2012. This is due to the fact that we don't have a lot of data on the years before 2011. Adding these years as well will only make our algorithm slow and we unwanted noise is generated. It is important to provide only important data to the algorithm, and avoid spamming it with non-relevant information or columns that do not contain data about many users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform integer dates to data type: date\n",
    "final1['registration_init_time'] = final1.registration_init_time.apply(lambda x: datetime.strptime(str(int(x)), \"%Y%m%d\").date() if pd.notnull(x) else \"NAN\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>city_1</th>\n",
       "      <th>city_3</th>\n",
       "      <th>city_4</th>\n",
       "      <th>city_5</th>\n",
       "      <th>city_6</th>\n",
       "      <th>city_7</th>\n",
       "      <th>...</th>\n",
       "      <th>city_19</th>\n",
       "      <th>city_20</th>\n",
       "      <th>city_21</th>\n",
       "      <th>city_22</th>\n",
       "      <th>reg_year_2012</th>\n",
       "      <th>reg_year_2013</th>\n",
       "      <th>reg_year_2014</th>\n",
       "      <th>reg_year_2015</th>\n",
       "      <th>reg_year_2016</th>\n",
       "      <th>reg_year_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=</td>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  bd  gender  registered_via  city_1  city_3  city_4  city_5  city_6  city_7      ...        city_19  city_20  city_21  city_22  reg_year_2012  \\\n",
       "0  Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=   0     NaN              11       1       0       0       0       0       0      ...              0        0        0        0              0   \n",
       "1  +tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=   0     NaN               7       1       0       0       0       0       0      ...              0        0        0        0              0   \n",
       "2  cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=   0     NaN              11       1       0       0       0       0       0      ...              0        0        0        0              0   \n",
       "3  9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=   0     NaN              11       1       0       0       0       0       0      ...              0        0        0        0              0   \n",
       "4  WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=  32  female               9       0       0       0       0       1       0      ...              0        0        0        0              0   \n",
       "\n",
       "   reg_year_2013  reg_year_2014  reg_year_2015  reg_year_2016  reg_year_2017  \n",
       "0              0              0              0              0              0  \n",
       "1              0              0              0              0              0  \n",
       "2              0              0              0              0              0  \n",
       "3              0              0              0              0              0  \n",
       "4              0              0              0              0              0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe containing the colum reg_year\n",
    "date = pd.DataFrame(columns=['reg_year'])\n",
    "#save the year of registration in it\n",
    "date.reg_year=pd.DatetimeIndex(final1['registration_init_time']).year\n",
    "\n",
    "#Drop variable registration_init_time in final1, as it is no longer needed\n",
    "final1=final1.drop('registration_init_time',axis=1)\n",
    "#Join the two dataframes\n",
    "final1=final1.join(date)\n",
    "\n",
    "#get one-hot encoding columns\n",
    "year_encode = pd.get_dummies(final1['reg_year'],prefix='reg_year')\n",
    "#Drop not so relevant years, see data exploraion file for members\n",
    "year_encode=year_encode.drop(['reg_year_2004','reg_year_2005','reg_year_2006','reg_year_2007','reg_year_2008','reg_year_2009','reg_year_2010','reg_year_2011'],axis=1)\n",
    "\n",
    "#Join and drop\n",
    "final1 = final1.join(year_encode)\n",
    "final1=final1.drop('reg_year',axis=1)\n",
    "\n",
    "final1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 One-hot encoding of registration method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to one-hot encode the registration method. Similarly to the \"city\"-variable, this feature contains integer values that have no numerical meaning. The algorithm will not be able to understand that the value in \"registered_via\" has no actual meaning. The algorithm will add a higher weight to high values, which would be wrong. This is why we need to one-hot encode the regisration method as well. Taking the data exploration into account, we decide to get rid of certain values for \"registration_via\" as they only represent a very small fraction of the data. As such, they are not relevant and will make the algorithm slow and inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>city_1</th>\n",
       "      <th>city_3</th>\n",
       "      <th>city_4</th>\n",
       "      <th>city_5</th>\n",
       "      <th>city_6</th>\n",
       "      <th>city_7</th>\n",
       "      <th>city_8</th>\n",
       "      <th>...</th>\n",
       "      <th>reg_year_2013</th>\n",
       "      <th>reg_year_2014</th>\n",
       "      <th>reg_year_2015</th>\n",
       "      <th>reg_year_2016</th>\n",
       "      <th>reg_year_2017</th>\n",
       "      <th>reg_3</th>\n",
       "      <th>reg_4</th>\n",
       "      <th>reg_7</th>\n",
       "      <th>reg_9</th>\n",
       "      <th>reg_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=</td>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  bd  gender  city_1  city_3  city_4  city_5  city_6  city_7  city_8   ...    reg_year_2013  reg_year_2014  reg_year_2015  reg_year_2016  \\\n",
       "0  Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=   0     NaN       1       0       0       0       0       0       0   ...                0              0              0              0   \n",
       "1  +tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=   0     NaN       1       0       0       0       0       0       0   ...                0              0              0              0   \n",
       "2  cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=   0     NaN       1       0       0       0       0       0       0   ...                0              0              0              0   \n",
       "3  9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=   0     NaN       1       0       0       0       0       0       0   ...                0              0              0              0   \n",
       "4  WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=  32  female       0       0       0       0       1       0       0   ...                0              0              0              0   \n",
       "\n",
       "   reg_year_2017  reg_3  reg_4  reg_7  reg_9  reg_11  \n",
       "0              0      0      0      0      0       1  \n",
       "1              0      0      0      1      0       0  \n",
       "2              0      0      0      0      0       1  \n",
       "3              0      0      0      0      0       1  \n",
       "4              0      0      0      0      1       0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the dummy columns\n",
    "reg_encode = pd.get_dummies(final1['registered_via'],prefix='reg')\n",
    "\n",
    "#drop the not so relevant columns (see data exploration file for members)\n",
    "reg_encode=reg_encode.drop(['reg_-1','reg_1','reg_2','reg_5','reg_6','reg_8','reg_10','reg_13','reg_14','reg_16','reg_17','reg_18','reg_19'],axis=1)\n",
    "\n",
    "#Join and drop\n",
    "final1 = final1.join(reg_encode)\n",
    "final1=final1.drop('registered_via',axis=1)\n",
    "\n",
    "final1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>city_1</th>\n",
       "      <th>city_3</th>\n",
       "      <th>city_4</th>\n",
       "      <th>city_5</th>\n",
       "      <th>city_6</th>\n",
       "      <th>city_7</th>\n",
       "      <th>city_8</th>\n",
       "      <th>...</th>\n",
       "      <th>reg_year_2013</th>\n",
       "      <th>reg_year_2014</th>\n",
       "      <th>reg_year_2015</th>\n",
       "      <th>reg_year_2016</th>\n",
       "      <th>reg_year_2017</th>\n",
       "      <th>reg_3</th>\n",
       "      <th>reg_4</th>\n",
       "      <th>reg_7</th>\n",
       "      <th>reg_9</th>\n",
       "      <th>reg_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=</td>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  bd  gender  city_1  city_3  city_4  city_5  city_6  city_7  city_8   ...    reg_year_2013  reg_year_2014  reg_year_2015  reg_year_2016  \\\n",
       "0  Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=   0     NaN       1       0       0       0       0       0       0   ...                0              0              0              0   \n",
       "1  +tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=   0     NaN       1       0       0       0       0       0       0   ...                0              0              0              0   \n",
       "2  cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=   0     NaN       1       0       0       0       0       0       0   ...                0              0              0              0   \n",
       "3  9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=   0     NaN       1       0       0       0       0       0       0   ...                0              0              0              0   \n",
       "4  WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=  32  female       0       0       0       0       1       0       0   ...                0              0              0              0   \n",
       "\n",
       "   reg_year_2017  reg_3  reg_4  reg_7  reg_9  reg_11  \n",
       "0              0      0      0      0      0       1  \n",
       "1              0      0      0      1      0       0  \n",
       "2              0      0      0      0      0       1  \n",
       "3              0      0      0      0      0       1  \n",
       "4              0      0      0      0      1       0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print which columns are left for registration metod \n",
    "reg_encode.head()\n",
    "final1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 Normalization of birthday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age of the users also plays a role in the likelihood of churning, as it was mentioned in the data exploration. In a first step, we get rid of the outliers, by setting al the values that are smaller than one and larger than 90 to 24. 24 corresponds to the median We just assume that a user is between 1 and 90 years old. Next we normalize the data (min-max normalization). The data is normalized, because the range of the values for our raw data varies widely between different features. To prevent a bad effect on the performance of the algorithm, we take the precautionary step to normalize it. In fact, some objective functions will not work properly if data is not normalized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd=final1.bd.copy()\n",
    "bd_df = pd.DataFrame(columns=['bd_norm'])\n",
    "bd_df.bd_norm=bd\n",
    "\n",
    "#set outliers to 24:\n",
    "mask=(bd_df.bd_norm<0)\n",
    "mask2=(bd_df.bd_norm>90)\n",
    "column_name='bd_norm'\n",
    "\n",
    "\n",
    "bd_df.loc[mask,column_name]=24\n",
    "bd_df.loc[mask2,column_name]=24\n",
    "\n",
    "\n",
    "#normalize\n",
    "bd_df.bd_norm=bd_df.bd_norm/90\n",
    "\n",
    "final1 = final1.join(bd_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.000000\n",
       "3    0.000000\n",
       "4    0.355556\n",
       "Name: bd_norm, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_df.bd_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 Young people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#We create a column with young people under 24, because they are more likely to churn\n",
    "#save bd in a vector for new feature later on\n",
    "bd=final1.bd\n",
    "\n",
    "#create indexes\n",
    "mask=(final1.bd<24)\n",
    "mask_not=(final1.bd<1)\n",
    "mask_not2=(final1.bd>23)\n",
    "\n",
    "column_name='bd'\n",
    "#change birthday indexes\n",
    "final1.loc[mask,column_name]=1\n",
    "final1.loc[mask_not,column_name]=0\n",
    "final1.loc[mask_not2,column_name]=0\n",
    "\n",
    "final1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Merge Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, the data is merged with the train and submission files and is tested for null values. Since many algorithms cannot handle NULL values (NaN), we need to replace them with different values that make sens in the context of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>bd</th>\n",
       "      <th>city_1</th>\n",
       "      <th>city_3</th>\n",
       "      <th>city_4</th>\n",
       "      <th>city_5</th>\n",
       "      <th>city_6</th>\n",
       "      <th>city_7</th>\n",
       "      <th>city_8</th>\n",
       "      <th>city_9</th>\n",
       "      <th>...</th>\n",
       "      <th>reg_year_2014</th>\n",
       "      <th>reg_year_2015</th>\n",
       "      <th>reg_year_2016</th>\n",
       "      <th>reg_year_2017</th>\n",
       "      <th>reg_3</th>\n",
       "      <th>reg_4</th>\n",
       "      <th>reg_7</th>\n",
       "      <th>reg_9</th>\n",
       "      <th>reg_11</th>\n",
       "      <th>bd_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  bd  city_1  city_3  city_4  city_5  city_6  city_7  city_8  city_9    ...     reg_year_2014  reg_year_2015  reg_year_2016  reg_year_2017  reg_3  \\\n",
       "0  Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=   0       1       0       0       0       0       0       0       0    ...                 0              0              0              0      0   \n",
       "1  +tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=   0       1       0       0       0       0       0       0       0    ...                 0              0              0              0      0   \n",
       "2  cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=   0       1       0       0       0       0       0       0       0    ...                 0              0              0              0      0   \n",
       "3  9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=   0       1       0       0       0       0       0       0       0    ...                 0              0              0              0      0   \n",
       "4  WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=  32       0       0       0       0       1       0       0       0    ...                 0              0              0              0      0   \n",
       "\n",
       "   reg_4  reg_7  reg_9  reg_11   bd_norm  \n",
       "0      0      0      0       1  0.000000  \n",
       "1      0      1      0       0  0.000000  \n",
       "2      0      0      0       1  0.000000  \n",
       "3      0      0      0       1  0.000000  \n",
       "4      0      0      1       0  0.355556  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping bd gender, regstered_via and regisration_init_time to test if city encoding helps algorithm performing\n",
    "final1=final1.drop(['gender'],axis=1)\n",
    "final1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before merging \"members\" with the train and test files, we need to check whether \"members\" contains any null values. However, the sum of the NaN's in the file is 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for null-values:\n",
    "final1.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loaded!\n",
      "test loaded!\n"
     ]
    }
   ],
   "source": [
    "#Load the training and submssion data in, so we can create 3 files to export for the final algorithm\n",
    "\n",
    "# From train.csv, we will extract the is_churn and use it as the y-label for training. \n",
    "train = pd.read_csv('data/train.csv')\n",
    "print('train loaded!')\n",
    "\n",
    "# From train_v2.csv (the churn data for march), we will extract the is_churn and use it as the y-label for test\n",
    "train_v2 = pd.read_csv('data/train_v2.csv')\n",
    "\n",
    "# From sample_submission_v2.csv, we will extract the msno's \n",
    "submission = pd.read_csv('data/sample_submission_v2.csv')\n",
    "print('test loaded!')\n",
    "\n",
    "#members_train1\n",
    "#members_train2\n",
    "#members_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the two train and the submission file in, we can merge them with members on \"msno\" to create three files called \"members_train1\", \"members_train2\" and \"members_total\". We need to merge the files retrieve the churn-information about the users and combine it with other data with have. While merging the files together, NULL values may be generated, because we use a left merge on the \"train\", \"train_v2\" and \"submission\" dataframe respectivaly. They may contain msno's that cannot be found in the \"members\"-file, and as such, NULL values in the corresponding rows are generated.\n",
    "To get rid of the NULL values, we need to iterate through our new feature engineered data frame and set the NaN's to 0 (or 0.26 for the birthdays). For the variables \"city\", \"registrated_via\" and \"reg_year\" 0 entries in every feature-engineered column will mean that we do not have any data. For the birthdays, we chose to set them to 0.26 (normalized representation of 24), because 24 represents a high-frquency value for the birthdays (this can be concluded by looking at the histogram in the data exploration section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a copy:\n",
    "final=final1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the bd-column, as it is not needed anymore\n",
    "final=final.drop('bd',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merges done!\n"
     ]
    }
   ],
   "source": [
    "#Merge the files together on \"msno\"\n",
    "members_train1 = pd.merge(train,final,on='msno',how='left')\n",
    "members_train2 = pd.merge(train_v2,final,on='msno',how='left')\n",
    "members_total = pd.merge(submission ,final,on='msno',how='left')\n",
    "print('merges done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3820410\n",
      "3629769\n",
      "3708573\n"
     ]
    }
   ],
   "source": [
    "#check for NaN's after merging\n",
    "print(members_train1.isnull().sum().sum())\n",
    "print(members_train2.isnull().sum().sum())\n",
    "print(members_total.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of null-values\n",
    "#Iterate through the final1 data frame and get rid of NaN's\n",
    "\n",
    "cities = ['city_1','city_3','city_4','city_5','city_6','city_7','city_8','city_9','city_10','city_11','city_12','city_13','city_14','city_15','city_16','city_17','city_18','city_19','city_20','city_21','city_22']\n",
    "for i in range(0,len(cities)):\n",
    "        inpt = cities[i]\n",
    "        members_train1[inpt]=members_train1[inpt].fillna(value=0)\n",
    "        members_train2[inpt]=members_train2[inpt].fillna(value=0)\n",
    "        members_total[inpt]=members_total[inpt].fillna(value=0)\n",
    "        \n",
    "reg_dates=['reg_year_2012','reg_year_2013','reg_year_2014','reg_year_2015','reg_year_2016','reg_year_2017']        \n",
    "for i in range(0,len(reg_dates)):\n",
    "        inpt = reg_dates[i]\n",
    "        members_train1[inpt]=members_train1[inpt].fillna(value=0)\n",
    "        members_train2[inpt]=members_train2[inpt].fillna(value=0)\n",
    "        members_total[inpt]=members_total[inpt].fillna(value=0)\n",
    "\n",
    "reg_meth=['reg_3','reg_4','reg_7','reg_9','reg_11']\n",
    "for i in range(0,len(reg_meth)):\n",
    "        inpt = reg_meth[i]\n",
    "        members_train1[inpt]=members_train1[inpt].fillna(value=0)\n",
    "        members_train2[inpt]=members_train2[inpt].fillna(value=0)\n",
    "        members_total[inpt]=members_total[inpt].fillna(value=0)     \n",
    "        \n",
    "members_train1['bd_norm']=members_train1['bd_norm'].fillna(value=0.26)\n",
    "members_train2['bd_norm']=members_train2['bd_norm'].fillna(value=0.26)\n",
    "members_total['bd_norm']=members_total['bd_norm'].fillna(value=0.26)     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#check for NaN's. Are there any NaN's left?\n",
    "print(members_train1.isnull().sum().sum())\n",
    "print(members_train2.isnull().sum().sum())\n",
    "print(members_total.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>city_1</th>\n",
       "      <th>city_3</th>\n",
       "      <th>city_4</th>\n",
       "      <th>city_5</th>\n",
       "      <th>city_6</th>\n",
       "      <th>city_7</th>\n",
       "      <th>city_8</th>\n",
       "      <th>city_9</th>\n",
       "      <th>...</th>\n",
       "      <th>reg_year_2014</th>\n",
       "      <th>reg_year_2015</th>\n",
       "      <th>reg_year_2016</th>\n",
       "      <th>reg_year_2017</th>\n",
       "      <th>reg_3</th>\n",
       "      <th>reg_4</th>\n",
       "      <th>reg_7</th>\n",
       "      <th>reg_9</th>\n",
       "      <th>reg_11</th>\n",
       "      <th>bd_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waLDQMmcOu2jLDaV1ddDkgCrB/jl6sD66Xzs0Vqax1Y=</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QA7uiXy8vIbUSPOkCf9RwQ3FsT8jVq2OxDr8zqa7bRQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fGwBva6hikQmTJzrbz/2Ezjm5Cth5jZUNvXigKK2AFA=</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mT5V8rEpa+8wuqi6x0DoVd3H5icMKkE9Prt49UlmK+4=</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XaPhtGLk/5UvvOYHcONTwsnH97P4eGECeq+BARGItRw=</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn  city_1  city_3  city_4  city_5  city_6  city_7  city_8  city_9    ...     reg_year_2014  reg_year_2015  reg_year_2016  reg_year_2017  \\\n",
       "0  waLDQMmcOu2jLDaV1ddDkgCrB/jl6sD66Xzs0Vqax1Y=         1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    ...               0.0            0.0            0.0            0.0   \n",
       "1  QA7uiXy8vIbUSPOkCf9RwQ3FsT8jVq2OxDr8zqa7bRQ=         1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    ...               0.0            0.0            0.0            0.0   \n",
       "2  fGwBva6hikQmTJzrbz/2Ezjm5Cth5jZUNvXigKK2AFA=         1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    ...               0.0            0.0            0.0            0.0   \n",
       "3  mT5V8rEpa+8wuqi6x0DoVd3H5icMKkE9Prt49UlmK+4=         1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    ...               0.0            0.0            0.0            0.0   \n",
       "4  XaPhtGLk/5UvvOYHcONTwsnH97P4eGECeq+BARGItRw=         1     0.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0    ...               0.0            0.0            0.0            0.0   \n",
       "\n",
       "   reg_3  reg_4  reg_7  reg_9  reg_11   bd_norm  \n",
       "0    0.0    0.0    0.0    1.0     0.0  0.400000  \n",
       "1    0.0    0.0    0.0    1.0     0.0  0.422222  \n",
       "2    0.0    0.0    0.0    1.0     0.0  0.300000  \n",
       "3    0.0    0.0    0.0    1.0     0.0  0.255556  \n",
       "4    0.0    0.0    0.0    1.0     0.0  0.300000  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members_train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! :)\n"
     ]
    }
   ],
   "source": [
    "#export file, can take up to 1 min\n",
    "members_train1.to_csv('data/members_feb.csv', index=False)\n",
    "members_train2.to_csv('data/members_mar.csv', index=False)\n",
    "members_total.to_csv('data/members_apr.csv', index=False)\n",
    "print(\"Done! :)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, every feature is tested for its performance with XGBoost. That way, we can decide on which features to select and which ones we should delete again. Furthemore we can try other benchmarking, such as taking a small sample for the data, or only dropping a single feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Feature testing in XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save members for the different months\n",
    "members_feb = members_train1.copy()\n",
    "members_mar = members_train2.copy()\n",
    "members_apr = members_total.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(992931, 35)\n",
      "(970960, 35)\n",
      "(907471, 35)\n"
     ]
    }
   ],
   "source": [
    "#print out the shapes\n",
    "print(members_feb.shape)\n",
    "print(members_mar.shape)\n",
    "print(members_apr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create two variables ul_1 and ul_2. These variales contain a sample of \"members_feb\" and \"members_mar\" respectively. In that way, we can generate smaller test and train files to increase the speed of testing, and to see how it reacts to smaller data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(992931, 35)\n",
      "(992931, 35)\n",
      "(970960, 35)\n",
      "(970960, 35)\n"
     ]
    }
   ],
   "source": [
    "print(members_feb.shape)\n",
    "ul_1 = members_feb.sample(frac=1)\n",
    "print(ul_1.shape)\n",
    "\n",
    "print(members_mar.shape)\n",
    "ul_2 = members_mar.sample(frac=1)\n",
    "print(ul_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost and logloss\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that calls XGBoost\n",
    "# Run XGBoost\n",
    "def xgb_boost(train,test,importance,depth,eta,num_it):\n",
    "    start = time.time()\n",
    "    if ('msno' in train.columns):\n",
    "        train = train.drop('msno',axis=1)\n",
    "    if ('msno' in test.columns):\n",
    "        test = test.drop('msno',axis=1)\n",
    "    X_train = train.drop('is_churn',axis=1)\n",
    "    y_train = train['is_churn']\n",
    "    X_test = test.drop('is_churn',axis=1)\n",
    "    y_test = test['is_churn']\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label = y_test)\n",
    "    param = {\n",
    "        #'max_depth': 3,  # the maximum depth of each tree. Try with max_depth: 2 to 10.\n",
    "        'max_depth': depth,\n",
    "        #'eta': 0.3,  # the training step for each iteration. Try with ETA: 0.1, 0.2, 0.3...\n",
    "        'eta': eta,\n",
    "        'silent': 1,  # logging mode - quiet\n",
    "        'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "        'num_class': 3}  # the number of classes that exist in this datset\n",
    "    #num_round = 20  # the number of training iterations. Try with num_round around few hundred!\n",
    "    num_round = num_it\n",
    "    #----------------\n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "    y_pred_xgb = bst.predict(dtest)\n",
    "    best_preds = np.asarray([np.argmax(line) for line in y_pred_xgb])\n",
    "    y_pred_xgb = y_pred_xgb[:,1] #Column 2 out of 3\n",
    "    print(\"(probs) Logloss for XGD Boost is: %.6f\"%log_loss(y_test,y_pred_xgb))\n",
    "    \n",
    "    if (importance == 1):\n",
    "        xgb.plot_importance(bst,max_num_features=10)\n",
    "        plt.show()\n",
    "    \n",
    "    #y_pred_xgb[y_pred_xgb>=0.5] = 1\n",
    "    #y_pred_xgb[y_pred_xgb<0.5] = 0\n",
    "    #print(\"(1 or 0) Logloss for XGD Boost is: %.6f\"%log_loss(y_test,y_pred_xgb))\n",
    "\n",
    "    print('XGB Time = %.0f'%(time.time() - start))\n",
    "    \n",
    "    return y_pred_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(probs) Logloss for XGD Boost is: 0.282287\n",
      "XGB Time = 37\n",
      "### over-fitting check: ###\n"
     ]
    }
   ],
   "source": [
    "#call xgboost with our train and test data\n",
    "#can be used to test out the parameters of xgboost\n",
    "y_pred_xgb=xgb_boost(ul_1,ul_2,0,3,0.3,40)\n",
    "print('### over-fitting check: ###')\n",
    "\n",
    "#xgb_boost(ul_sample_1,ul_sample_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we are going to run xgbboost with every feaure except for one. As such we can see if the feature in question will actually improve the score or not. If our logloss gets worse without the feature in question, we can conclude that the feature is actually important and should be included in our prediction model. We create a loop that iterates through every single features and then drops it. XGBoost is called without the feature and the logloss is printed out. This is repeated until every feature is tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### city_1 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.285027\n",
      "XGB Time = 26\n",
      "\n",
      "### city_3 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 25\n",
      "\n",
      "### city_4 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284197\n",
      "XGB Time = 26\n",
      "\n",
      "### city_5 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 25\n",
      "\n",
      "### city_6 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 21\n",
      "\n",
      "### city_7 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 21\n",
      "\n",
      "### city_8 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 22\n",
      "\n",
      "### city_9 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 21\n",
      "\n",
      "### city_10 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 21\n",
      "\n",
      "### city_11 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 22\n",
      "\n",
      "### city_12 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 21\n",
      "\n",
      "### city_13 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284232\n",
      "XGB Time = 21\n",
      "\n",
      "### city_14 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 21\n",
      "\n",
      "### city_15 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 21\n",
      "\n",
      "### city_16 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 21\n",
      "\n",
      "### city_17 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 22\n",
      "\n",
      "### city_18 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 26\n",
      "\n",
      "### city_19 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 26\n",
      "\n",
      "### city_20 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 23\n",
      "\n",
      "### city_21 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 25\n",
      "\n",
      "### city_22 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 23\n",
      "\n",
      "### reg_year_2012 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 22\n",
      "\n",
      "### reg_year_2013 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284283\n",
      "XGB Time = 22\n",
      "\n",
      "### reg_year_2014 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284280\n",
      "XGB Time = 22\n",
      "\n",
      "### reg_year_2015 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284599\n",
      "XGB Time = 23\n",
      "\n",
      "### reg_year_2016 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284620\n",
      "XGB Time = 21\n",
      "\n",
      "### reg_year_2017 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284973\n",
      "XGB Time = 22\n",
      "\n",
      "### reg_3 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284213\n",
      "XGB Time = 22\n",
      "\n",
      "### reg_4 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284273\n",
      "XGB Time = 22\n",
      "\n",
      "### reg_7 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284746\n",
      "XGB Time = 22\n",
      "\n",
      "### reg_9 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284262\n",
      "XGB Time = 22\n",
      "\n",
      "### reg_11 removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.284205\n",
      "XGB Time = 22\n",
      "\n",
      "### bd_norm removed ###\n",
      "(probs) Logloss for XGD Boost is: 0.286655\n",
      "XGB Time = 22\n"
     ]
    }
   ],
   "source": [
    "# columns selection\n",
    "eng_columns = np.array(list(ul_1.drop(columns=['is_churn','msno'],axis=1)))\n",
    "\n",
    "for i in range(0,len(eng_columns)):\n",
    "    inpt = eng_columns[i]\n",
    "    data_input = ul_1.drop(inpt,axis=1)\n",
    "    data_outupt = ul_2.drop(inpt,axis=1)\n",
    "    print('\\n###',inpt,'removed ###')\n",
    "\n",
    "    xgb_boost(data_input,data_outupt,0,3,0.3,20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we test every feature alone to see its immediate effect on the prediction. Simlararly to the previous part, we create a loop that iterates through our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### city_1 ###\n",
      "(probs) Logloss for XGD Boost is: 0.236006\n",
      "XGB Time = 6\n",
      "\n",
      "### city_3 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237730\n",
      "XGB Time = 6\n",
      "\n",
      "### city_4 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237505\n",
      "XGB Time = 6\n",
      "\n",
      "### city_5 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237413\n",
      "XGB Time = 6\n",
      "\n",
      "### city_6 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237644\n",
      "XGB Time = 6\n",
      "\n",
      "### city_7 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237744\n",
      "XGB Time = 5\n",
      "\n",
      "### city_8 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237683\n",
      "XGB Time = 6\n",
      "\n",
      "### city_9 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237724\n",
      "XGB Time = 6\n",
      "\n",
      "### city_10 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237708\n",
      "XGB Time = 5\n",
      "\n",
      "### city_11 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237716\n",
      "XGB Time = 5\n",
      "\n",
      "### city_12 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237649\n",
      "XGB Time = 6\n",
      "\n",
      "### city_13 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237554\n",
      "XGB Time = 6\n",
      "\n",
      "### city_14 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237710\n",
      "XGB Time = 5\n",
      "\n",
      "### city_15 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237600\n",
      "XGB Time = 5\n",
      "\n",
      "### city_16 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237742\n",
      "XGB Time = 6\n",
      "\n",
      "### city_17 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237739\n",
      "XGB Time = 5\n",
      "\n",
      "### city_18 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237724\n",
      "XGB Time = 5\n",
      "\n",
      "### city_19 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237744\n",
      "XGB Time = 5\n",
      "\n",
      "### city_20 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237743\n",
      "XGB Time = 5\n",
      "\n",
      "### city_21 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237692\n",
      "XGB Time = 6\n",
      "\n",
      "### city_22 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237604\n",
      "XGB Time = 5\n",
      "\n",
      "### reg_year_2012 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237736\n",
      "XGB Time = 5\n",
      "\n",
      "### reg_year_2013 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237656\n",
      "XGB Time = 6\n",
      "\n",
      "### reg_year_2014 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237626\n",
      "XGB Time = 5\n",
      "\n",
      "### reg_year_2015 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237740\n",
      "XGB Time = 5\n",
      "\n",
      "### reg_year_2016 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237672\n",
      "XGB Time = 5\n",
      "\n",
      "### reg_year_2017 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237424\n",
      "XGB Time = 6\n",
      "\n",
      "### reg_3 ###\n",
      "(probs) Logloss for XGD Boost is: 0.234507\n",
      "XGB Time = 5\n",
      "\n",
      "### reg_4 ###\n",
      "(probs) Logloss for XGD Boost is: 0.233418\n",
      "XGB Time = 6\n",
      "\n",
      "### reg_7 ###\n",
      "(probs) Logloss for XGD Boost is: 0.228209\n",
      "XGB Time = 6\n",
      "\n",
      "### reg_9 ###\n",
      "(probs) Logloss for XGD Boost is: 0.236509\n",
      "XGB Time = 6\n",
      "\n",
      "### reg_11 ###\n",
      "(probs) Logloss for XGD Boost is: 0.237744\n",
      "XGB Time = 5\n",
      "\n",
      "### bd_norm ###\n",
      "(probs) Logloss for XGD Boost is: 0.231995\n",
      "XGB Time = 7\n"
     ]
    }
   ],
   "source": [
    "# columns selectione\n",
    "eng_columns = np.array(list(ul_1.drop(columns=['is_churn','msno'],axis=1)))\n",
    "\n",
    "for i in range(0,len(eng_columns)):\n",
    "    inpt = eng_columns[i]\n",
    "    data_input = ul_1[[inpt,'is_churn']]\n",
    "    data_output = ul_1[[inpt,'is_churn']]\n",
    "    print('\\n###',inpt,'###')\n",
    "    xgb_boost(data_input,data_output,0,3,0.3,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  is_churn                                          msno\n",
      "0     None  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=\n",
      "1     None  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=\n",
      "2     None  rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=\n",
      "3     None  WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=\n",
      "4     None  aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=\n",
      "                                           msno is_churn\n",
      "0  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=     None\n",
      "1  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=     None\n",
      "2  rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=     None\n",
      "3  WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=     None\n",
      "4  aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=     None\n",
      "msno        907471\n",
      "is_churn         0\n",
      "dtype: int64\n",
      "Done! :-)\n"
     ]
    }
   ],
   "source": [
    "#Prepare submission file\n",
    "#y_pred_xgb = xgb_boost(total_data,user_logs_apr,0,1)\n",
    "my_submission = pd.DataFrame({'msno': members_apr.msno, 'is_churn': y_pred_xgb})\n",
    "print(my_submission.head())\n",
    "cols = my_submission.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "my_submission = my_submission[cols]\n",
    "print(my_submission.head())\n",
    "print(my_submission.count())\n",
    "\n",
    "my_submission.to_csv('submission.csv', index=False)\n",
    "print('Done! :-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
