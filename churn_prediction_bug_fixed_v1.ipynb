{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Solution (for transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning library\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "#import XGBOOST Libraries\n",
    "#import xgboost as xgb\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "#Configure Panda\n",
    "pd.options.display.width = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and pre-processing data\n",
    "### !!! ATTENTION: In order to load the following files you first need to completely run the latest versions of Feature_Engineering_Members.ipynb and Feature_Engineering_Transactions.ipynb. !!!\n",
    "### 2.1 Load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load data in\n",
    "train = pd.read_csv('data/train_v2.csv')\n",
    "test = pd.read_csv('data/sample_submission_v2.csv')\n",
    "transactions = pd.read_csv('data/final_transactions.csv')\n",
    "final_members=pd.read_csv('data/final_members.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Merge the different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating datasets witgh input&outputs\n",
    "train_data = pd.merge(train,final_members,on='msno',how='left')\n",
    "train_data = pd.merge(train_data,transactions,how='left',on='msno',left_index=True, right_index=True)\n",
    "\n",
    "# Creating datasets with only inputs\n",
    "# Note that the submission_v2.csv file does NOT contain ouputs (they are all 0)\n",
    "test_data = pd.merge(test,final_members,on='msno',how='left')\n",
    "test_data = pd.merge(test_data,transactions,how='left',on='msno',left_index=True, right_index=True)\n",
    "\n",
    "#print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msno                           0\n",
      "is_churn                       0\n",
      "city_1                    109993\n",
      "city_3                    109993\n",
      "city_4                    109993\n",
      "city_5                    109993\n",
      "city_6                    109993\n",
      "city_7                    109993\n",
      "city_8                    109993\n",
      "city_9                    109993\n",
      "city_10                   109993\n",
      "city_11                   109993\n",
      "city_12                   109993\n",
      "city_13                   109993\n",
      "city_14                   109993\n",
      "city_15                   109993\n",
      "city_16                   109993\n",
      "city_17                   109993\n",
      "city_18                   109993\n",
      "city_19                   109993\n",
      "city_20                   109993\n",
      "city_21                   109993\n",
      "city_22                   109993\n",
      "reg_name                  109993\n",
      "reg_month                 109993\n",
      "actual_amount_paid             0\n",
      "is_auto_renew                  0\n",
      "transaction_date               0\n",
      "membership_expire_date         0\n",
      "is_cancel                      0\n",
      "                           ...  \n",
      "plan_list_price_150            0\n",
      "plan_list_price_180            0\n",
      "plan_list_price_210            0\n",
      "plan_list_price_265            0\n",
      "plan_list_price_298            0\n",
      "plan_list_price_300            0\n",
      "plan_list_price_350            0\n",
      "plan_list_price_400            0\n",
      "plan_list_price_447            0\n",
      "plan_list_price_450            0\n",
      "plan_list_price_477            0\n",
      "plan_list_price_480            0\n",
      "plan_list_price_500            0\n",
      "plan_list_price_536            0\n",
      "plan_list_price_596            0\n",
      "plan_list_price_600            0\n",
      "plan_list_price_699            0\n",
      "plan_list_price_799            0\n",
      "plan_list_price_894            0\n",
      "plan_list_price_930            0\n",
      "plan_list_price_1000           0\n",
      "plan_list_price_1150           0\n",
      "plan_list_price_1200           0\n",
      "plan_list_price_1260           0\n",
      "plan_list_price_1299           0\n",
      "plan_list_price_1300           0\n",
      "plan_list_price_1399           0\n",
      "plan_list_price_1599           0\n",
      "plan_list_price_1788           0\n",
      "plan_list_price_2000           0\n",
      "Length: 149, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for null values\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msno                      0\n",
      "is_churn                  0\n",
      "city_1                    0\n",
      "city_3                    0\n",
      "city_4                    0\n",
      "city_5                    0\n",
      "city_6                    0\n",
      "city_7                    0\n",
      "city_8                    0\n",
      "city_9                    0\n",
      "city_10                   0\n",
      "city_11                   0\n",
      "city_12                   0\n",
      "city_13                   0\n",
      "city_14                   0\n",
      "city_15                   0\n",
      "city_16                   0\n",
      "city_17                   0\n",
      "city_18                   0\n",
      "city_19                   0\n",
      "city_20                   0\n",
      "city_21                   0\n",
      "city_22                   0\n",
      "reg_name                  0\n",
      "reg_month                 0\n",
      "actual_amount_paid        0\n",
      "is_auto_renew             0\n",
      "transaction_date          0\n",
      "membership_expire_date    0\n",
      "is_cancel                 0\n",
      "                         ..\n",
      "plan_list_price_150       0\n",
      "plan_list_price_180       0\n",
      "plan_list_price_210       0\n",
      "plan_list_price_265       0\n",
      "plan_list_price_298       0\n",
      "plan_list_price_300       0\n",
      "plan_list_price_350       0\n",
      "plan_list_price_400       0\n",
      "plan_list_price_447       0\n",
      "plan_list_price_450       0\n",
      "plan_list_price_477       0\n",
      "plan_list_price_480       0\n",
      "plan_list_price_500       0\n",
      "plan_list_price_536       0\n",
      "plan_list_price_596       0\n",
      "plan_list_price_600       0\n",
      "plan_list_price_699       0\n",
      "plan_list_price_799       0\n",
      "plan_list_price_894       0\n",
      "plan_list_price_930       0\n",
      "plan_list_price_1000      0\n",
      "plan_list_price_1150      0\n",
      "plan_list_price_1200      0\n",
      "plan_list_price_1260      0\n",
      "plan_list_price_1299      0\n",
      "plan_list_price_1300      0\n",
      "plan_list_price_1399      0\n",
      "plan_list_price_1599      0\n",
      "plan_list_price_1788      0\n",
      "plan_list_price_2000      0\n",
      "Length: 149, dtype: int64\n",
      "msno                      0\n",
      "is_churn                  0\n",
      "city_1                    0\n",
      "city_3                    0\n",
      "city_4                    0\n",
      "city_5                    0\n",
      "city_6                    0\n",
      "city_7                    0\n",
      "city_8                    0\n",
      "city_9                    0\n",
      "city_10                   0\n",
      "city_11                   0\n",
      "city_12                   0\n",
      "city_13                   0\n",
      "city_14                   0\n",
      "city_15                   0\n",
      "city_16                   0\n",
      "city_17                   0\n",
      "city_18                   0\n",
      "city_19                   0\n",
      "city_20                   0\n",
      "city_21                   0\n",
      "city_22                   0\n",
      "reg_name                  0\n",
      "reg_month                 0\n",
      "actual_amount_paid        0\n",
      "is_auto_renew             0\n",
      "transaction_date          0\n",
      "membership_expire_date    0\n",
      "is_cancel                 0\n",
      "                         ..\n",
      "plan_list_price_150       0\n",
      "plan_list_price_180       0\n",
      "plan_list_price_210       0\n",
      "plan_list_price_265       0\n",
      "plan_list_price_298       0\n",
      "plan_list_price_300       0\n",
      "plan_list_price_350       0\n",
      "plan_list_price_400       0\n",
      "plan_list_price_447       0\n",
      "plan_list_price_450       0\n",
      "plan_list_price_477       0\n",
      "plan_list_price_480       0\n",
      "plan_list_price_500       0\n",
      "plan_list_price_536       0\n",
      "plan_list_price_596       0\n",
      "plan_list_price_600       0\n",
      "plan_list_price_699       0\n",
      "plan_list_price_799       0\n",
      "plan_list_price_894       0\n",
      "plan_list_price_930       0\n",
      "plan_list_price_1000      0\n",
      "plan_list_price_1150      0\n",
      "plan_list_price_1200      0\n",
      "plan_list_price_1260      0\n",
      "plan_list_price_1299      0\n",
      "plan_list_price_1300      0\n",
      "plan_list_price_1399      0\n",
      "plan_list_price_1599      0\n",
      "plan_list_price_1788      0\n",
      "plan_list_price_2000      0\n",
      "Length: 149, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Get rid of null-values\n",
    "\n",
    "#For train data\n",
    "#Set city null values to o in train data\n",
    "cities = ['city_1','city_3','city_4','city_5','city_6','city_7','city_8','city_9','city_10','city_11','city_12','city_13','city_14','city_15','city_16','city_17','city_18','city_19','city_20','city_21','city_22']\n",
    "for i in range(0,len(cities)):\n",
    "        inpt = cities[i]\n",
    "        train_data[inpt]=train_data[inpt].fillna(value=0)\n",
    "        test_data[inpt]=test_data[inpt].fillna(value=0)\n",
    "\n",
    "#Set registration dates null values to o in train data\n",
    "train_data[['reg_name','reg_month']] = train_data[['reg_name','reg_month']].fillna(value=0)\n",
    "test_data[['reg_name','reg_month']] = test_data[['reg_name','reg_month']].fillna(value=0)\n",
    "\n",
    "#check for null values\n",
    "print(train_data.isnull().sum())\n",
    "print(test_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unwanted columns (this may change with new insights or new code!)\n",
    "unwanted = ['msno','actual_amount_paid','transaction_date','membership_expire_date', 'diff_plan_actual','reg_name','reg_name']\n",
    "#Before dropping the msno of test, we need to save it for the sumission\n",
    "msno = test.msno\n",
    "train_data = train_data.drop(unwanted, axis=1)\n",
    "test_data = test_data.drop(unwanted, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970960, 142)\n",
      "(970960,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting input/output data into train and test sets in order to check efficiency of our models\n",
    "data_input = train_data.drop('is_churn',axis=1)\n",
    "data_output = train_data['is_churn']\n",
    "print(data_input.shape)\n",
    "print(data_output.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.2, random_state=42)\n",
    "\n",
    "# Removing is_churn (as it's all dummy zeros) from test data\n",
    "test_input = test_data.drop('is_churn',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Testing out prediction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted!\n",
      "Prediction done!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'log_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-8e17d68932f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Prediction done!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Logloss for Random Forrest is: %.2f\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m## I think we should use the logloss to measure our accuracy, as it is the same then they use on Kaggle. Also, to use accuracy, we need our input to be only 0's and 1's, thus it is not a very accurate assesment description of our model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'log_loss' is not defined"
     ]
    }
   ],
   "source": [
    "# Random Forrest, no training data\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "print('Model fitted!')\n",
    "y_pred_f = model.predict(x_test)\n",
    "print('Prediction done!')\n",
    "print(\"Logloss for Random Forrest is: %.2f\"%log_loss(y_test,y_pred_f))\n",
    "\n",
    "## I think we should use the logloss to measure our accuracy, as it is the same then they use on Kaggle. Also, to use accuracy, we need our input to be only 0's and 1's, thus it is not a very accurate assesment description of our model\n",
    "#predictions = [round(value) for value in y_pred]\n",
    "#accuracy = accuracy_score(y_test, predictions)\n",
    "#print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted!\n",
      "Prediction done!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'log_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-0b6495408e55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_pred_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Prediction done!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Logloss for Linear Regression is: %.2f\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'log_loss' is not defined"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "print('Model fitted!')\n",
    "# Make predicitons for test data\n",
    "y_pred_l = model.predict(x_test)\n",
    "y_pred_l = np.absolute(y_pred_l)\n",
    "print('Prediction done!')\n",
    "print(\"Logloss for Linear Regression is: %.2f\"%log_loss(y_test,y_pred_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run AdaBoost\n",
    "model_abr = AdaBoostRegressor()\n",
    "model_abr.fit(x_train, y_train)\n",
    "y_pred_abr = model_abr.predict(x_test)\n",
    "print(\"Logloss for AdaBoost is: %.2f\"%log_loss(y_test,y_pred_abr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SGDRegressor (really bad)\n",
    "model_sgd = SGDRegressor()\n",
    "#model_sgd.fit(x_train, y_train)\n",
    "#y_pred_sgd = model_sgd.predict(x_test)\n",
    "print(\"Logloss for SGDRegressor is: %.2f\"%log_loss(y_test,y_pred_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GradientBoostingRegressor (very slow)\n",
    "model_gbr = GradientBoostingRegressor()\n",
    "#model_gbr.fit(x_train, y_train)\n",
    "#y_pred_gbr = model_gbr.predict(x_test)\n",
    "print(\"Logloss for GradientBoostingRegressor is: %.2f\"%log_loss(y_test,y_pred_gbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#XG Boost\n",
    "dtrain = xgb.DMatrix(x_train, label = y_train)\n",
    "dtest = xgb.DMatrix(x_test, label = y_test)\n",
    "print('Done.')\n",
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree. Try with max_depth: 2 to 10.\n",
    "    'eta': 0.3,  # the training step for each iteration. Try with ETA: 0.1, 0.2, 0.3...\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations. Try with num_round around few hundred!\n",
    "#----------------\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "print('Modeling done!')\n",
    "\n",
    "y_pred_xgb = bst.predict(dtest)\n",
    "print('Prediction done!')\n",
    "\n",
    "best_preds = np.asarray([np.argmax(line) for line in y_pred_xgb])\n",
    "\n",
    "y_pred_xgb = y_pred_xgb[:,1] #Column 2 out of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from  sklearn.metrics import log_loss\n",
    "print(\"Logloss for XGBoost is: %.3f\"%log_loss(y_test,y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Running the best model on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "model.fit(data_input, data_output)\n",
    "y_pred_l = model.predict(test_input)\n",
    "y_pred_l = np.absolute(y_pred_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_churn                                          msno\n",
      "0  0.056911  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=\n",
      "1  0.122503  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=\n",
      "2  0.121942  rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=\n",
      "3  0.054859  WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=\n",
      "4  0.055925  aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=\n",
      "                                           msno  is_churn\n",
      "0  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=  0.056911\n",
      "1  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=  0.122503\n",
      "2  rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=  0.121942\n",
      "3  WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=  0.054859\n",
      "4  aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=  0.055925\n",
      "msno        907471\n",
      "is_churn    907471\n",
      "dtype: int64\n",
      "Done! :-)\n"
     ]
    }
   ],
   "source": [
    "#Prepare submission file\n",
    "my_submission = pd.DataFrame({'msno': msno, 'is_churn': y_pred_l})\n",
    "#think about changing y_pred_1 if you want to use a diffrenet algorithm\n",
    "#y_pred_1 was one of the reasons for the previous bug\n",
    "print(my_submission.head())\n",
    "cols = my_submission.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "my_submission = my_submission[cols]\n",
    "print(my_submission.head())\n",
    "print(my_submission.count())\n",
    "\n",
    "my_submission.to_csv('submission.csv', index=False)\n",
    "print('Done! :-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
